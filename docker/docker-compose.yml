#version: '3.9'

services:
  dl:
    image: daniinxorchenabo/itmo-prod-dl-labs-env:lighting-cpu-consumer-latest
    build:
      context: ..
      dockerfile: ./docker/lighting.Dockerfile
      target: consumer_production_build
      args:
        REQUIREMENTS_FILE: ${BUILD_BACKEND_REQUIREMENTS_FILE:-useless}

    container_name: consumer
    depends_on:
      hbase-rest:
        condition: service_healthy
      vault:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - BACKEND_HOST_URL=dl
      - DB_HOST=hbase-rest
      - VAULT_HOST=vault
      - KAFKA_PRODUCER=false
      - KAFKA_CONSUMER=true
      - DOCKER_USE_GPU=false
      - KAFKA_PARTITION_COUNT
      - KAFKA_TOPIC
      - KAFKA_PORT
      - KAFKA_HOST
      - VAULT_SECRETS_PATH
      - VAULT_SECRETS_NAME
      - VAULT_UNSEAL_KEY_1
      - VAULT_UNSEAL_KEY_2
      - VAULT_UNSEAL_KEY_3
      - VAULT_UNSEAL_KEY_4
      - VAULT_UNSEAL_KEY_5
      - VAULT_ROOT_TOKEN
      - BACKEND_MICROSERVICE_DEFAULT_PROTOCOL
      - BACKEND_PORT
      - BACKEND_APP_WORKERS_COUNT
      - TEST_FROM_NETWORK
    volumes: #!override
      - type: bind
        source: ../neural/logs/prod
        target: /workspace/NN/neural/logs/prod
    command: >
      bash -c "
      python consumer.py
      "
    networks:
      - db_network
      - production_network
      - kafka_network
      - vault_network

  producer:
    image: daniinxorchenabo/itmo-prod-dl-labs-env:lighting-cpu-producer-latest
    build:
      context: ..
      dockerfile: ./docker/lighting.Dockerfile
      target: producer_production_build
      args:
        REQUIREMENTS_FILE: ${BUILD_BACKEND_REQUIREMENTS_FILE:-useless}

    container_name: producer
    depends_on:
      hbase-rest:
        condition: service_healthy
      vault:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - BACKEND_HOST_URL=producer
      - DB_HOST=hbase-rest
      - VAULT_HOST=vault
      - KAFKA_PRODUCER=true
      - KAFKA_CONSUMER=false
      - DOCKER_USE_GPU=false
      - KAFKA_PARTITION_COUNT
      - KAFKA_TOPIC
      - KAFKA_PORT
      - KAFKA_HOST
      - VAULT_SECRETS_PATH
      - VAULT_SECRETS_NAME
      - VAULT_UNSEAL_KEY_1
      - VAULT_UNSEAL_KEY_2
      - VAULT_UNSEAL_KEY_3
      - VAULT_UNSEAL_KEY_4
      - VAULT_UNSEAL_KEY_5
      - VAULT_ROOT_TOKEN
      - BACKEND_MICROSERVICE_DEFAULT_PROTOCOL
      - BACKEND_PORT
      - BACKEND_APP_WORKERS_COUNT
      - TEST_FROM_NETWORK
    volumes: #!override
      - type: bind
        source: ../neural/logs/prod
        target: /workspace/NN/neural/logs/prod
    command: >
      bash -c "
      fastapi run --workers ${BACKEND_APP_WORKERS_COUNT:-1} --port ${BACKEND_PORT:-8000} --host 0.0.0.0  producer.py
      "
    networks:
      - production_network
      - db_network
      - kafka_network
      - vault_network
    ports: #!override
      - "0.0.0.0:${BACKEND_PORT:-8000}:${BACKEND_PORT:-8000}"
    healthcheck:
      test: curl --fail http://producer:${BACKEND_PORT:-8000}/healthcheck || exit 1
      interval: 10s
      timeout: 10s
      start_period: 10s
      retries: 10

  kdc:
    depends_on:
      - vault
    build: ./kdc
    container_name: kerberos-kdc
    image: daniinxorchenabo/itmo-dl-labs-kerberos-kdc:latest
    ports:
      - "88:88"
      - "749:749"
    volumes:
      - kdc-data:/var/kerberos/krb5kdc
      - ./kdc/keytabs:/etc/krb5kdc  # Монтирование каталога с keytab-файлами
      - ./hbase/conf:/etc/hbase/conf

    restart: unless-stopped

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - kafka_network
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: /usr/bin/kafka-broker-api-versions --bootstrap-server localhost:9092  > /dev/null 2>&1
      interval: 5s
      start_period: 10s
      timeout: 5s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - db_network
      - kafka_network
    ports:
      - "2181:2181"

  hbase:
    build: ./hbase
    image: daniinxorchenabo/itmo-dl-labs-hbase:latest
    container_name: hbase-secure
    environment:
      - HBASE_CLUSTER_DISTRIBUTED=true
      - HBASE_MANAGES_ZOOKEEPER=false
    networks:
      - db_network
    ports:
      - "16010:16010"  # веб-интерфейс HMaster
      - "16020:16020"  # порт регионсерверов (если требуется)
    volumes:
      - hbase-data:/opt/hbase/data
      - hbase-logs:/hbase/logs
#      - ./kdc/keytabs:/opt/hbase/kerberos  # монтирование каталога с keytab
#      - ./hbase/conf:/opt/hbase/conf
    depends_on:
      - zookeeper
      - vault
    # Запускаем HBase Master. Команда запускает HBase Master,
    # который при распределённом режиме использует внешний ZooKeeper.
    command: ["bash", "-c", "/hbase/bin/start-hbase.sh master && tail -f /hbase/logs/hbase--master-*.log"]
    restart: unless-stopped

  hbase-rest:
    build: ./hbase
    image: daniinxorchenabo/itmo-dl-labs-hbase:latest
    container_name: hbase-rest
    environment:
      - HBASE_CLUSTER_DISTRIBUTED=true
      - HBASE_MANAGES_ZOOKEEPER=false
    networks:
      - db_network
    ports:
      - "${DB_PORT:-8080}:${DB_PORT:-8080}"  # Порт для HBase REST сервера
    volumes:
      - hbase-data:/hbase/data
      - hbase-logs:/hbase/logs
#      - ./kdc/keytabs:/opt/hbase/kerberos  # монтирование каталога с keytab
#      - ./hbase/conf:/opt/hbase/conf

    depends_on:
      - zookeeper
      - hbase
      - vault
    # Запускаем HBase REST в foreground на порту 8080
    command: ["bash", "-c", "/hbase/bin/hbase rest start -p 8080 && tail -f /hbase/logs/hbase--rest-*.log"]
    restart: unless-stopped
    healthcheck:
      test: curl --fail http://hbase-rest:${DB_PORT:-8080}/ || exit 1
      interval: 10s
      timeout: 10s
      start_period: 10s
      retries: 10

  vault:
    image: daniinxorchenabo/itmo-dl-labs-vault:latest
    build: ./vault
    container_name: vault
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: "http://127.0.0.1:8200"
    volumes:
      - ./vault/vault-config.hcl:/vault/config/vault-config.hcl
      - ./vault/init_vault.sh:/vault/init_vault.sh
      - vault-data:/vault/data
    cap_add:
      - IPC_LOCK
    command: "vault server -config=/vault/config/vault-config.hcl"
    networks:
      - vault_network
    healthcheck:
      test: curl --fail http://vault:8200/v1/sys/seal-status || exit 1
      interval: 10s
      timeout: 10s
      start_period: 10s
      retries: 10

volumes:
  kdc-data:
    name: ${CONTAINER_PREFIX:-unsetted_prefix}-kdc-data
  hbase-data:
    name: ${CONTAINER_PREFIX:-unsetted_prefix}-hbase-data
  hbase-logs:
    name: ${CONTAINER_PREFIX:-unsetted_prefix}-hbase-logs
  vault-data:
    name: ${CONTAINER_PREFIX:-unsetted_prefix}-vault_t3

networks:
  production_network:
    driver: "bridge"
#    enable_ipv6: true
    internal: false
    name: "${CONTAINER_PREFIX:-unsetted_prefix}-production-network"
  db_network:
    driver: "bridge"
#    enable_ipv6: true
    internal: true
    name: "${CONTAINER_PREFIX:-unsetted_prefix}-db-network"
  kafka_network:
    driver: "bridge"
#    enable_ipv6: true
    internal: true
    name: "${CONTAINER_PREFIX:-unsetted_prefix}-kafka-network"
  vault_network:
    driver: "bridge"
#    enable_ipv6: true
    internal: true
    name: "${CONTAINER_PREFIX:-unsetted_prefix}-vault-network"
  spark-network:
    driver: bridge
    internal: false
    name: "${CONTAINER_PREFIX:-unsetted_prefix}-spark-network"