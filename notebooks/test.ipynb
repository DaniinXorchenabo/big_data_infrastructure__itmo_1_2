{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T12:54:29.103471Z",
     "start_time": "2025-02-26T12:54:26.937315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "from src.code.code.init_neural import device\n",
    "!pip install kagglehub[pandas-datasets]"
   ],
   "id": "705e6d5acc612d0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.11/site-packages (0.3.10)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from kagglehub[pandas-datasets]) (24.2)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from kagglehub[pandas-datasets]) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from kagglehub[pandas-datasets]) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from kagglehub[pandas-datasets]) (4.67.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from kagglehub[pandas-datasets]) (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas->kagglehub[pandas-datasets]) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->kagglehub[pandas-datasets]) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->kagglehub[pandas-datasets]) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub[pandas-datasets]) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub[pandas-datasets]) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub[pandas-datasets]) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub[pandas-datasets]) (2025.1.31)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T11:48:13.477976Z",
     "start_time": "2025-02-27T11:48:13.381738Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "ROOT_DIR = '/workspace/NN'\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "import shutil\n",
    "import kagglehub\n",
    "import torch\n",
    "\n",
    "dataset_path = os.path.join(ROOT_DIR, 'neural', 'datasets', 'fashionmnist')\n",
    "logs_path = os.path.join(ROOT_DIR, 'neural', 'logs')\n",
    "csv_file = os.path.join(dataset_path, 'fashion-mnist_train.csv')\n",
    "prod_weights_path = os.path.join(ROOT_DIR, 'neural', 'weights', 'prod')\n",
    "test_weights_path = os.path.join(ROOT_DIR, 'neural', 'weights', 'lab_1')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T12:50:25.512231Z",
     "start_time": "2025-02-26T12:50:23.765724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.isdir(dataset_path):\n",
    "    source_dir = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "    target_dir = dataset_path\n",
    "    shutil.move(source_dir, target_dir)"
   ],
   "id": "932879f1c983e01e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T12:59:32.968779Z",
     "start_time": "2025-02-26T12:59:31.451948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "data"
   ],
   "id": "6b23761a8eb4a2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T13:03:19.763614Z",
     "start_time": "2025-02-26T13:03:18.207386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Путь к CSV-файлу с данными.\n",
    "            transform (callable, optional): Трансформации для изображения.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Получаем строку с данными\n",
    "        sample = self.data.iloc[idx]\n",
    "\n",
    "        # Предполагается, что в CSV первая колонка — метка,\n",
    "        # а остальные 28*28 пикселей записаны последовательно.\n",
    "        label = int(sample.iloc[0])\n",
    "        img_array = sample.iloc[1:].values.astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "        # Если трансформации заданы, применяем их.\n",
    "        if self.transform:\n",
    "            img = self.transform(img_array)\n",
    "        else:\n",
    "            # Преобразуем в тензор, добавляя размер канала (1, 28, 28)\n",
    "            img = torch.tensor(img_array, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "\n",
    "        return img, label\n",
    "\n",
    "'''\n",
    "0 Футболка/топ\n",
    "1 Брюки\n",
    "2 Пуловер\n",
    "3 Платье\n",
    "4 Слой\n",
    "5 Сандалий\n",
    "6 Рубашка\n",
    "7 Кроссовок\n",
    "8 Мешков\n",
    "9 Ботинок на щиколотке\n",
    "'''\n",
    "\n",
    "# Пример использования:\n",
    "if __name__ == \"__main__\":\n",
    "    # Определяем трансформации: конвертация numpy массива в PIL Image и затем в тензор\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Путь к CSV-файлу (отредактируй путь в соответствии с расположением файла)\n",
    "    train_csv = csv_file\n",
    "\n",
    "    # Создаём объект датасета\n",
    "    train_dataset = FashionMNISTDataset(csv_file=train_csv, transform=transform)\n",
    "\n",
    "    # Создаём DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Пример итерации по DataLoader'у\n",
    "    for images, labels in train_loader:\n",
    "        print(f\"Batch images shape: {images.shape}, labels shape: {labels.shape}\")\n",
    "        # Здесь можно добавить код для обучения модели\n",
    "        break\n"
   ],
   "id": "8108692ba62791db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([64, 1, 28, 28]), labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:37:48.029892Z",
     "start_time": "2025-02-27T11:35:34.642964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "# Определяем лёгкую сверточную сеть для FashionMNIST\n",
    "class LightweightFashionMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightweightFashionMNIST, self).__init__()\n",
    "        # Входное изображение: 1 x 28 x 28\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)   # -> 16 x 28 x 28\n",
    "        self.pool  = nn.MaxPool2d(2, 2)                             # -> 16 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)    # -> 32 x 14 x 14\n",
    "        # После второго pooling: 32 x 7 x 7\n",
    "        self.fc1   = nn.Linear(32 * 7 * 7, 64)\n",
    "        self.fc2   = nn.Linear(64, 10)  # 10 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Определяем LightningModule\n",
    "class FashionMNISTLitModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super(FashionMNISTLitModel, self).__init__()\n",
    "        self.model = LightweightFashionMNIST()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Метрики для обучения и валидации\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task='multiclass',num_classes=10)\n",
    "        self.val_precision = torchmetrics.Precision(task='multiclass',num_classes=10, average='macro')\n",
    "        self.val_recall = torchmetrics.Recall(task='multiclass', num_classes=10, average='macro')\n",
    "        self.val_auroc = torchmetrics.AUROC(task='multiclass',num_classes=10)\n",
    "        self.confmat = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=10)\n",
    "        self.val_f1 = MulticlassF1Score( num_classes=10, average='macro')  # Добавлена метрика F1\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_accuracy.update(preds, y)\n",
    "        self.log('train/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Вместо training_epoch_end, используем on_train_epoch_end (без аргументов)\n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.log('train/epoch_time', epoch_time)\n",
    "        acc = self.train_accuracy.compute()\n",
    "        self.log('train/accuracy', acc, prog_bar=True)\n",
    "        self.train_accuracy.reset()\n",
    "        self.log('train/lr', self.learning_rate)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "        self.val_precision.update(preds, y)\n",
    "        self.val_recall.update(preds, y)\n",
    "        self.val_auroc.update(F.softmax(logits, dim=1), y)\n",
    "        self.val_f1.update(preds, y)  # Обновление F1 метрики\n",
    "\n",
    "        self.confmat.update(preds, y)\n",
    "        self.log('val/loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        acc = self.val_accuracy.compute()\n",
    "        prec = self.val_precision.compute()\n",
    "        rec = self.val_recall.compute()\n",
    "        f1 = self.val_f1.compute()  # Вычисление F1 метрики\n",
    "        auroc = self.val_auroc.compute()\n",
    "        self.log('val/accuracy', acc, prog_bar=True)\n",
    "        self.log('val/precision', prec)\n",
    "        self.log('val/recall', rec)\n",
    "        self.log('val/auroc', auroc)\n",
    "        self.log('val/f1', f1)  # Логирование F1 метрики\n",
    "\n",
    "        # Логируем матрицу ошибок как изображение в TensorBoard\n",
    "        confmat = self.confmat.compute().cpu().numpy()\n",
    "        fig = self.plot_confusion_matrix(confmat)\n",
    "        self.logger.experiment.add_figure(\"Confusion Matrix\", fig, self.current_epoch)\n",
    "\n",
    "        self.val_accuracy.reset()\n",
    "        self.val_precision.reset()\n",
    "        self.val_recall.reset()\n",
    "        self.val_auroc.reset()\n",
    "        self.val_f1.reset()  # Сброс F1 метрики\n",
    "        self.confmat.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def plot_confusion_matrix(self, confmat):\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        im = ax.imshow(confmat, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        ax.set(xticks=np.arange(confmat.shape[1]),\n",
    "               yticks=np.arange(confmat.shape[0]),\n",
    "               xticklabels=np.arange(10),\n",
    "               yticklabels=np.arange(10),\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label',\n",
    "               title='Confusion Matrix')\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        thresh = confmat.max() / 2.\n",
    "        for i in range(confmat.shape[0]):\n",
    "            for j in range(confmat.shape[1]):\n",
    "                ax.text(j, i, format(confmat[i, j], 'd'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if confmat[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "# Подготовка данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST(root=dataset_path, train=True, download=True, transform=transform)\n",
    "val_dataset   = FashionMNIST(root=dataset_path, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "# Инициализируем модель\n",
    "learn_id = str(uuid.uuid4())\n",
    "model_name = 'fashion_MNIST_lite'\n",
    "model = FashionMNISTLitModel(learning_rate=1e-3)\n",
    "# Настраиваем TensorBoard логгер\n",
    "logger = TensorBoardLogger(\n",
    "        logs_path,\n",
    "        name=model_name,\n",
    "        version=learn_id,\n",
    "        sub_dir=(_sd:=f\"{(u_:=datetime.utcnow().strftime('%Y_%m_%d__%H_%M_%S'))}\"),\n",
    ")\n",
    "# Настраиваем колбэк для сохранения модели\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=(_tg_m:='val/auroc'),       # Метрика для мониторинга\n",
    "    dirpath=test_weights_path, # Каталог для сохранения моделей\n",
    "    filename=f'{model_name}_{_sd}_{learn_id}' + '-{epoch:02d}-{' + _tg_m + ':.2f}', # Имя файла\n",
    "    save_top_k=1,             # Сохранять только лучшую модель\n",
    "    mode='max'                # Минимизировать monitored метрику\n",
    ")\n",
    "\n",
    "# Создаем тренер PyTorch Lightning\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "# Запускаем обучение\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ],
   "id": "d6dc0e65c5043d0c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /workspace/NN/my_checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type                      | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | model          | LightweightFashionMNIST   | 105 K  | train\n",
      "1 | train_accuracy | MulticlassAccuracy        | 0      | train\n",
      "2 | val_accuracy   | MulticlassAccuracy        | 0      | train\n",
      "3 | val_precision  | MulticlassPrecision       | 0      | train\n",
      "4 | val_recall     | MulticlassRecall          | 0      | train\n",
      "5 | val_auroc      | MulticlassAUROC           | 0      | train\n",
      "6 | confmat        | MulticlassConfusionMatrix | 0      | train\n",
      "7 | val_f1         | MulticlassF1Score         | 0      | train\n",
      "---------------------------------------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.423     Total estimated model params size (MB)\n",
      "13        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c406233257a4037b92033e201412e5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "976dfe3182574a859d7167f8a8e2539c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9096972e47e3460594b5fb3b525dcff0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c23017223f5c43e2bbdd7c5aa55352fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b65c272228bd49c6a098370273d0de92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e311df8cf6db4650b31e36eb147981eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f620079769e94844a51867949fa8b29a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38e311c9e9e04a6bbcb3fd3e45f02f5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5c90b0c184544e4a1ae301f988bfd21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4db813e6050f467dae34b41308362906"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94e63ae8cfc34c55b3f0514ea63ba6d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfb37197cf7242239a66aafe8fa6378d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af40b83b56934c2cb7bfb6a82abfd704"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d1ae49ffbed405ab8f342dc71bd76e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78d4d24522c34f868bda8e0df1b32d90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8909ea233cf4c3b97e0630b7f0f3abe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "673ce6a9f70b4ca6ba99164df5dc6cb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd153ac4f76545df95582e9aed477ffe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86de007572a04411a9c36c57097db5ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fe2f230049c46ad8cea0d8bbb2fc41b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "515a831a02d2426488e7254202f4f2f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e228b6eee3547cdbdffedc552446e61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:42:01.458545Z",
     "start_time": "2025-02-27T11:42:01.335382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model_path = checkpoint_callback.best_model_path\n",
    "\n",
    "target_path_to_model = os.path.join(prod_weights_path, os.path.split(os.path.split(best_model_path)[0])[1] + '_' + os.path.split(best_model_path)[1])\n",
    "\n",
    "shutil.move(best_model_path, target_path_to_model)\n"
   ],
   "id": "ad0d59906d598353",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/NN/my_checkpoints/fashion_MNIST_lite_2025_02_27__11_35_34_af5d8943-4cf8-4204-b7a3-f39e5a49e673-epoch=10-val/auroc=0.99.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m/usr/local/lib/python3.11/shutil.py:853\u001B[0m, in \u001B[0;36mmove\u001B[0;34m(src, dst, copy_function)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 853\u001B[0m     os\u001B[38;5;241m.\u001B[39mrename(src, real_dst)\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/workspace/NN/my_checkpoints/fashion_MNIST_lite_2025_02_27__11_35_34_af5d8943-4cf8-4204-b7a3-f39e5a49e673-epoch=10-val/auroc=0.99.ckpt' -> '/workspace/NN/neural/prod'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m best_model_path \u001B[38;5;241m=\u001B[39m checkpoint_callback\u001B[38;5;241m.\u001B[39mbest_model_path\n\u001B[0;32m----> 2\u001B[0m \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmove\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprod_weights_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m path_to_model \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(prod_weights_path, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplit(best_model_path)[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      4\u001B[0m trained_model \u001B[38;5;241m=\u001B[39m FashionMNISTLitModel\u001B[38;5;241m.\u001B[39mload_from_checkpoint(\n\u001B[1;32m      5\u001B[0m     checkpoint_path\u001B[38;5;241m=\u001B[39mpath_to_model,\n\u001B[1;32m      6\u001B[0m     map_location\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(device\u001B[38;5;241m=\u001B[39mdevice)  \u001B[38;5;66;03m# или 'cuda' для GPU\u001B[39;00m\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/shutil.py:873\u001B[0m, in \u001B[0;36mmove\u001B[0;34m(src, dst, copy_function)\u001B[0m\n\u001B[1;32m    871\u001B[0m         rmtree(src)\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 873\u001B[0m         \u001B[43mcopy_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_dst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    874\u001B[0m         os\u001B[38;5;241m.\u001B[39munlink(src)\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m real_dst\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/shutil.py:448\u001B[0m, in \u001B[0;36mcopy2\u001B[0;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(dst):\n\u001B[1;32m    447\u001B[0m     dst \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dst, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(src))\n\u001B[0;32m--> 448\u001B[0m \u001B[43mcopyfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_symlinks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_symlinks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    449\u001B[0m copystat(src, dst, follow_symlinks\u001B[38;5;241m=\u001B[39mfollow_symlinks)\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dst\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/shutil.py:256\u001B[0m, in \u001B[0;36mcopyfile\u001B[0;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[1;32m    254\u001B[0m     os\u001B[38;5;241m.\u001B[39msymlink(os\u001B[38;5;241m.\u001B[39mreadlink(src), dst)\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 256\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(src, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fsrc:\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(dst, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fdst:\n\u001B[1;32m    259\u001B[0m                 \u001B[38;5;66;03m# macOS\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/workspace/NN/my_checkpoints/fashion_MNIST_lite_2025_02_27__11_35_34_af5d8943-4cf8-4204-b7a3-f39e5a49e673-epoch=10-val/auroc=0.99.ckpt'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:48:18.968145Z",
     "start_time": "2025-02-27T11:48:18.849363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_path_to_model = '/workspace/NN/neural/weights/prod/fashion_MNIST_lite_2025_02_27__11_35_34_af5d8943-4cf8-4204-b7a3-f39e5a49e673-epoch=10-val_auroc=0.99.ckpt'\n",
    "trained_model = FashionMNISTLitModel.load_from_checkpoint(\n",
    "    checkpoint_path=target_path_to_model,\n",
    "    map_location=torch.device(device=device)  # или 'cuda' для GPU\n",
    ")"
   ],
   "id": "d0032a0d8dd89056",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "46df42f2c98392c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
