{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T20:48:04.132531Z",
     "start_time": "2025-04-15T20:48:02.196540Z"
    }
   },
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %reload_ext autoreload\n",
    "\n",
    "import os\n",
    "ROOT_DIR = '/workspace/NN'\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "import shutil\n",
    "import kagglehub\n",
    "import torch\n",
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "\n",
    "dataset_path = os.path.join(ROOT_DIR, 'neural', 'datasets', 'spark', 'test_1')\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "print(socket.gethostbyname(\"spark-master\"))\n",
    "driver_host = socket.gethostbyname(socket.gethostname())\n",
    "print(driver_host)\n",
    "driver_host = socket.gethostbyname(\"spark-master\")\n",
    "print(driver_host)\n",
    "driver_host = \"producer\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = f\"\"\"\n",
    "--master spark://spark-master:7077\n",
    "--conf spark.driver.host={driver_host}\n",
    "--conf spark.driver.port=45555\n",
    "--conf spark.executor.memory=1G\n",
    "--conf spark.executor.cores=1\n",
    "pyspark-shell\n",
    "\"\"\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'  # путь к Python в контейнере\n",
    "# os.environ['SPARK_HOME'] = '/opt/spark'            # путь к Spark, укажи реальный\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "\n",
    "MONGO_USER = os.environ[\"MONGO_USER\"]\n",
    "MONGO_PASS = os.environ[\"MONGO_PASSWORD\"]\n",
    "MONGO_ADDR = f\"{MONGO_USER}:{MONGO_PASS}@mongodb:27017\"  # :27017\n",
    "\n",
    "def spark_app_generator(name):\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .appName(name) \\\n",
    "         .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "        .config(\"spark.executor.memory\", \"1g\") \\\n",
    "        .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.3.0\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", f\"mongodb://{MONGO_ADDR}\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", f\"mongodb://{MONGO_ADDR}\") \\\n",
    "        .getOrCreate()\n",
    "    return spark  # /openfoodfacts.products\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.18.0.3\n",
      "172.22.0.5\n",
      "172.18.0.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MONGO_ADDR",
   "id": "2a9216cf5f849e8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.sql.types import (StructType, StructField,\n",
    "                               StringType, IntegerType, MapType,\n",
    "                               DoubleType\n",
    "                               )\n",
    "\n",
    "# Пример определения схемы. Настройте схему под структуру ваших данных.\n",
    "custom_schema = StructType([\n",
    "    StructField(\"_id\", StringType(), True),\n",
    "    StructField(\"product_name\", StringType(), True),\n",
    "    # Если nutriments представляет собой динамические поля, лучше сохранить его как MapType.\n",
    "    StructField(\"nutriments\", MapType(StringType(), StringType()), True),\n",
    "    # Если есть другие поля, укажите их типы.\n",
    "    StructField(\"quantity\", StringType(), True),\n",
    "     StructField(\"ingredients_sweeteners_n\", IntegerType(), True),\n",
    "     StructField(\"ingredients_percent_analysis\", IntegerType(), True),\n",
    "     StructField(\"ingredients_non_nutritive_sweeteners_n\", IntegerType(), True),\n",
    "     StructField(\"ingredients_n\", IntegerType(), True),\n",
    "    StructField(\"ingredients_from_palm_oil_n\", IntegerType(), True),\n",
    "    StructField(\"ingredients_from_or_that_may_be_from_palm_oil_n\", IntegerType(), True),\n",
    "    StructField(\"additives_n\", IntegerType(), True),\n",
    "    StructField(\"unique_scans_n\", IntegerType(), True),\n",
    "    StructField(\"scans_n\", IntegerType(), True),\n",
    "    StructField(\"rev\", IntegerType(), True),\n",
    "    StructField(\"popularity_key\", IntegerType(), True),\n",
    "    StructField(\"packagings_n\", IntegerType(), True),\n",
    "    StructField(\"packagings_complete\", IntegerType(), True),\n",
    "    StructField(\"nutrition_score_warning_no_fiber\", IntegerType(), True),\n",
    "    StructField(\"nutrition_score_warning_fruits_vegetables_nuts_estimate\", IntegerType(), True),\n",
    "    StructField(\"nutrition_score_beverage\", IntegerType(), True),\n",
    "    StructField(\"nutriscore_score_opposite\", IntegerType(), True),\n",
    "    StructField(\"nutriscore_score\", IntegerType(), True),\n",
    "    StructField(\"environmental_score_score\", IntegerType(), True),\n",
    "    StructField(\"completeness\", DoubleType(), True),\n",
    "    StructField(\"complete\", IntegerType(), True),\n",
    "\n",
    "])\n",
    "\n",
    "spark = spark_app_generator('test_mongo_reading')\n",
    "df = spark.read.schema(custom_schema).format(\"mongodb\") \\\n",
    "  .options(host=\"mongo:27017\", database=\"off\", collection='products').load()  # , database=\"off\", collection='products'\n",
    "\n",
    "# Просмотр схемы и первых строк\n",
    "df.printSchema()\n",
    "df.show(20)\n"
   ],
   "id": "4893b1c50680e696"
  },
  {
   "cell_type": "code",
   "id": "593e4532f56fb43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:39:17.833171Z",
     "start_time": "2025-04-15T19:39:17.771554Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T20:58:10.042109Z",
     "start_time": "2025-04-15T20:54:39.300596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "spark = spark_app_generator('test_mongo_data_analysis')\n",
    "df = spark.read.schema(custom_schema).format(\"mongodb\") \\\n",
    "  .options(host=\"mongo:27017\", database=\"off\", collection='products').load()\n",
    "\n",
    "# Выбор числовых признаков\n",
    "numeric_features = ['nutriscore_score', 'environmental_score_score', 'popularity_key', 'popularity_key', \"rev\"]\n",
    "\n",
    "# Удаление строк с пропущенными значениями\n",
    "df_clean = df.select(numeric_features).dropna()\n",
    "\n",
    "# Сбор признаков в вектор\n",
    "assembler = VectorAssembler(inputCols=numeric_features, outputCol=\"features_assembled\")\n",
    "df_vector = assembler.transform(df_clean)\n",
    "\n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler(inputCol=\"features_assembled\", outputCol=\"features\")\n",
    "scaler_model = scaler.fit(df_vector)\n",
    "df_scaled = scaler_model.transform(df_vector)"
   ],
   "id": "ca3b1aa8c6b6f361",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T21:20:13.972771Z",
     "start_time": "2025-04-15T21:01:59.340210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Обучение модели k-средних\n",
    "kmeans = KMeans().setK(4).setSeed(1).setFeaturesCol(\"features\")\n",
    "model = kmeans.fit(df_scaled)\n",
    "\n",
    "# Предсказание кластеров\n",
    "predictions = model.transform(df_scaled)\n",
    "\n",
    "# Оценка модели\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "\n",
    "# Центры кластеров\n",
    "centers = model.clusterCenters()\n",
    "for idx, center in enumerate(centers):\n",
    "    print(f\"Cluster {idx} center: {center}\")"
   ],
   "id": "c0b6b13c448b00de",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 21:09:27 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "[Stage 60:===================================================>(1015 + 2) / 1017]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.4595071839606593\n",
      "Cluster 0 center: [0.23533113 2.1008176  0.00316603 0.00316603 0.52181049]\n",
      "Cluster 1 center: [ 0.97125113  2.1844216  -2.40970803 -2.40970803  1.36017413]\n",
      "Cluster 2 center: [1.9046912  1.639037   0.00211394 0.00211394 0.46630675]\n",
      "Cluster 3 center: [1.0371697  2.11290436 2.08015347 2.08015347 0.99501358]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Не забудьте остановить SparkSession по завершении работы\n",
    "spark.stop()"
   ],
   "id": "f1ad6ce7ea151e20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
